{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BbG1U2DjUs_qE_9c0VIp45CBxGG7I2bW",
      "authorship_tag": "ABX9TyOGfSOqmVW9k2jyqNigJw1k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikithap14/Deep-Learning-Based-Author-Genre-Attribution/blob/main/genre__dataset_csv_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/cleanedgenredataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRKFM33VDmeY",
        "outputId": "6dbf6c22-1d31-4e53-ca31-dcba1185bb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/cleanedgenredataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iym0JNdQCiui",
        "outputId": "f1c0523d-c0e7-405e-fc35-06c49b65bab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Across Asia on a Bicycle.txt'\n",
            "'A Manual of the Operations of Surgery.txt'\n",
            "'Andersens Fairy Tales .txt'\n",
            "'Anomalies and Curiosities of Medicine.txt'\n",
            "'Beyond the Black River.txt'\n",
            "'Fat and Blood.txt'\n",
            "'Flappers and Philosophers.txt'\n",
            "'From Egypt to Japan.txt'\n",
            "'Handbook of Summer Athletic Sports.txt'\n",
            "'Hints for Lovers.txt'\n",
            "'Just So Stories (1).txt'\n",
            " Kidnapped.txt\n",
            "'Life of Harriet Beecher Stowe.txt'\n",
            "'Memoirs of Joseph Grimaldi.txt'\n",
            "'Modern Religious Cults and Movements.txt'\n",
            "'Mothers Remedies.txt'\n",
            "'Myth, Ritual and Religion, Vol. 1 (of 2).txt'\n",
            "'New Ideas for American Boys; The Jack of All Trades.txt'\n",
            "'Nooks and Corners of Old England.txt'\n",
            "'Old Granny Fox (1).txt'\n",
            "'On Love.txt'\n",
            "'Primitive Love and Love-Stories.txt'\n",
            "'Prison Memoirs of an Anarchist.txt'\n",
            "'Sea and Sardinia.txt'\n",
            "'Six Months at the Cape.txt'\n",
            "'Surgical Anatomy.txt'\n",
            "'The Big Trip Up Yonder.txt'\n",
            "'The Blue Star.txt'\n",
            "'The Book of Love.txt'\n",
            "'The Everlasting Man.txt'\n",
            "'The Every-day Life of Abraham Lincoln.txt'\n",
            "'The House on the Borderland.txt'\n",
            "'The Idea of God in Early Religions.txt'\n",
            "'The Lady of the Lake.txt'\n",
            "'The Life and Adventures of Santa Claus (1).txt'\n",
            "'The Memoirs of Victor Hugo.txt'\n",
            "'The Prussian Officer.txt'\n",
            "'The Queens cadet and other tales.txt'\n",
            "'The School of Recreation (1684 edition).txt'\n",
            "'The Sportswomans Library, Vol. 1 of 2.txt'\n",
            "'The Tale of Peter Rabbit (1).txt'\n",
            "'The Worlds Greatest Books — Volume 13 — Religion and Philosophy.txt'\n",
            " Triplanetary.txt\n",
            "'Walkers manly exercises.txt'\n",
            " Whirligigs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oIlfzrq_SSE",
        "outputId": "5f37b474-8d4a-46ff-ada3-6e8a200b0aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(filepath, min_char):\n",
        "    \"\"\"Convert text file to a list of sentences.\n",
        "    \n",
        "    Args:\n",
        "    filepath: string. Filepath of text file.\n",
        "    min_char: int. Minimum number of characters required for a sentence to be\n",
        "    included.\n",
        "    Returns:\n",
        "    sentences: list of strings. List of sentences containined in the text file.\n",
        "    \"\"\"\n",
        "    # Load data into string variable and remove new line characters\n",
        "    file = open(filepath, \"r\", encoding=\"utf8\")\n",
        "    text = file.read().replace('\\n', ' ')\n",
        "    text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n",
        "    text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n",
        "    file.close()\n",
        "    \n",
        "    # Split text into a list of sentences\n",
        "    sentences = tokenize.sent_tokenize(text)\n",
        "    \n",
        "    # Remove sentences that are less than min_char long\n",
        "    sentences = [sent for sent in sentences if len(sent) >= min_char]\n",
        "\n",
        "    return list(sentences)"
      ],
      "metadata": {
        "id": "P8KO0hIX_YfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_char = 5\n",
        "\n",
        "\n",
        "\n",
        "childrens = split_text('Just So Stories (1).txt', min_char = min_char)\\\n",
        "        + split_text('Old Granny Fox (1).txt', min_char = min_char)\\\n",
        "        + split_text('The Tale of Peter Rabbit (1).txt', min_char = min_char)\\\n",
        "        + split_text('The Life and Adventures of Santa Claus (1).txt', min_char = min_char)\\\n",
        "        + split_text('Andersens Fairy Tales .txt', min_char = min_char)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "literature = split_text('Flappers and Philosophers.txt', min_char = min_char)\\\n",
        "        + split_text('Kidnapped.txt', min_char = min_char)\\\n",
        "        + split_text('The Prussian Officer.txt', min_char = min_char)\\\n",
        "        + split_text('Whirligigs.txt', min_char = min_char)\\\n",
        "        + split_text('The Queens cadet and other tales.txt', min_char = min_char)\n",
        "        \n",
        "\n",
        "religion = split_text('The Worlds Greatest Books — Volume 13 — Religion and Philosophy.txt', min_char = min_char)\\\n",
        "        + split_text('The Idea of God in Early Religions.txt', min_char = min_char)\\\n",
        "        + split_text('The Everlasting Man.txt', min_char = min_char)\\\n",
        "        + split_text('Myth, Ritual and Religion, Vol. 1 (of 2).txt', min_char = min_char)\\\n",
        "        + split_text('Modern Religious Cults and Movements.txt', min_char = min_char)\n",
        "\n",
        "romantic = split_text('Hints for Lovers.txt', min_char = min_char)\\\n",
        "        + split_text('On Love.txt', min_char = min_char)\\\n",
        "        + split_text('Primitive Love and Love-Stories.txt', min_char = min_char)\\\n",
        "        + split_text('The Book of Love.txt', min_char = min_char)\\\n",
        "        + split_text('The Lady of the Lake.txt', min_char = min_char)\n",
        "\n",
        "sciencefic = split_text('Beyond the Black River.txt', min_char = min_char)\\\n",
        "        + split_text('The Big Trip Up Yonder.txt', min_char = min_char)\\\n",
        "        + split_text('The Blue Star.txt', min_char = min_char)\\\n",
        "        + split_text('The House on the Borderland.txt', min_char = min_char)\\\n",
        "        + split_text('Triplanetary.txt', min_char = min_char)\n",
        "\n",
        "sports = split_text('Handbook of Summer Athletic Sports.txt', min_char = min_char)\\\n",
        "        + split_text('New Ideas for American Boys; The Jack of All Trades.txt', min_char = min_char)\\\n",
        "        + split_text('The School of Recreation (1684 edition).txt', min_char = min_char)\\\n",
        "        + split_text('The Sportswomans Library, Vol. 1 of 2.txt', min_char = min_char)\\\n",
        "        + split_text('Walkers manly exercises.txt', min_char = min_char)\n",
        "\n",
        "travel = split_text('Across Asia on a Bicycle.txt', min_char = min_char)\\\n",
        "        + split_text('From Egypt to Japan.txt', min_char = min_char)\\\n",
        "        + split_text('Nooks and Corners of Old England.txt', min_char = min_char)\\\n",
        "        + split_text('Sea and Sardinia.txt', min_char = min_char)\\\n",
        "        + split_text('Six Months at the Cape.txt', min_char = min_char)\n",
        "\n"
      ],
      "metadata": {
        "id": "QdTOWSNC_hV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print length of each list\n",
        "\n",
        "text_dict = { 'Childrens': childrens,\n",
        "             'Literature': literature,\n",
        "             'Religion': religion, \n",
        "             'Romantic': romantic ,\n",
        "             'Sciencefic': sciencefic, \n",
        "             'Sports': sports,\n",
        "             'Travel': travel }\n",
        "\n",
        "for key in text_dict.keys():\n",
        "    print(key, ':', len(text_dict[key]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18LHX44ZMTxX",
        "outputId": "b1b69658-7b80-4413-d2fb-ea7afb802f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Childrens : 7316\n",
            "Literature : 22418\n",
            "Religion : 18388\n",
            "Romantic : 24048\n",
            "Sciencefic : 15971\n",
            "Sports : 10638\n",
            "Travel : 18296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "np.random.seed(1)\n",
        "\n",
        "# Set length parameter\n",
        "max_len = 7000\n",
        "\n",
        "# Select sentences\n",
        "names = [childrens,literature,religion,romantic,sciencefic, sports,travel ]\n",
        "combined = []\n",
        "\n",
        "for name in names:\n",
        "    name = np.random.choice(name, max_len, replace = False)\n",
        "    combined += list(name)\n",
        "\n",
        "print('The length of the combined list is:', len(combined))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvzG0PN0TjGv",
        "outputId": "5ee4bb6b-0bcb-4a35-d675-49593dee383b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the combined list is: 49000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels =  ['Childrens']*max_len + ['Literature']*max_len\\\n",
        "         + ['Religion']*max_len + ['Romantic']*max_len + ['Sciencefic']*max_len + ['Sports']*max_len\\\n",
        "          + ['Travel']*max_len\n",
        "\n",
        "print('The length of the labels list is:', len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFrh-61GHtD6",
        "outputId": "cda1f1d5-ecb8-4ac8-ee35-cd86106a6c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the labels list is: 49000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "random.seed(3)\n",
        "\n",
        "# Randomly shuffle data\n",
        "zipped = list(zip(combined, labels))\n",
        "random.shuffle(zipped)\n",
        "combined, labels = zip(*zipped)"
      ],
      "metadata": {
        "id": "KP21-9OcH-YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pandas dataframe\n",
        "out_data = pd.DataFrame()\n",
        "out_data['text'] = combined\n",
        "out_data['genre'] = labels\n",
        "\n",
        "print(out_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k492oHopIBwL",
        "outputId": "3ca93746-1dfa-4543-cc15-2eee016e9576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text       genre\n",
            "0  “Oh no, oh no, my dear demoiselle, you must no...  Sciencefic\n",
            "1  Some evenings I used to bring home two or thre...      Sports\n",
            "2  Elsewhere Lowell has given another admirable d...    Romantic\n",
            "3                                            so hoe!  Literature\n",
            "4  Immediately after dinner, he must resume his e...      Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export as a csv file\n",
        "out_data.to_csv('genre_data_clean1.csv', index=False)"
      ],
      "metadata": {
        "id": "HVYPVTynIGWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}